{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0731243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langgraph.graph import StateGraph , START , END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage , AIMessage , SystemMessage\n",
    "from typing import TypedDict , Annotated\n",
    "from pydantic import BaseModel , Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25322176",
   "metadata": {},
   "source": [
    "### Tutorial Overview: Text Analysis Pipeline\n",
    "In this tutorial, we'll demonstrate the power of LangGraph by building a multi-step text analysis pipeline. Our use case will focus on processing a given text through three key stages:\n",
    "\n",
    "Text Classification: We'll categorize the input text into predefined categories (e.g., News, Blog, Research, or Other). \\\n",
    "Entity Extraction: We'll identify and extract key entities such as persons, organizations, and locations from the text. \\\n",
    "Text Summarization: Finally, we'll generate a concise summary of the input text. \\\n",
    "Title : We will also generate the title of the talk \\\n",
    "Content : We will join each one of them to create a blog  \\\n",
    "This pipeline showcases how LangGraph can be used to create a modular, extensible workflow for natural language processing tasks. By the end of this tutorial, you'll understand how to construct a graph-based application that can be easily modified or expanded for various text analysis needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "996994bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    text_classification: Annotated[str, None]\n",
    "    entity_extraction: Annotated[dict[str, list[str]], None]\n",
    "    summary: Annotated[str, None]\n",
    "    title: Annotated[str, None]\n",
    "    content: Annotated[str, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b6be49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0 , max_completion_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dbffd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# --- Pydantic Schemas and LLMs ---\n",
    "\n",
    "class TextClassification(BaseModel):\n",
    "    \"\"\"\n",
    "    Classify the text into one of the following categories: News, Blog, Research, or Other.\n",
    "    \"\"\"\n",
    "    category: Literal[\"News\", \"Blog\", \"Research\", \"Other\"] = Field(description=\"The category of the text\")\n",
    "\n",
    "text_classification_llm = model.with_structured_output(TextClassification)\n",
    "\n",
    "class EntityExtraction(BaseModel):\n",
    "    \"\"\"\n",
    "    Extract entities from the text. Return a dictionary with keys 'person', 'organisation', and 'location'.\n",
    "    Each key should map to a list of the corresponding entities found in the text.\n",
    "    Example: {\"person\": [\"John Doe\"], \"organisation\": [\"OpenAI\"], \"location\": [\"San Francisco\", \"India\"]}\n",
    "    If no entities are found, return an empty dictionary. If one key doesn't have a value, return an empty list for that key.\n",
    "    \"\"\"\n",
    "    entities: dict[str, list[str]] = Field(\n",
    "        description=\"A dictionary with keys 'person', 'organisation', and 'location', each mapping to a list of extracted entities.\"\n",
    "    )\n",
    "\n",
    "entity_extraction_llm = model.with_structured_output(EntityExtraction)\n",
    "\n",
    "class TextSummarization(BaseModel):\n",
    "    \"\"\"\n",
    "    Summarize the text in a concise manner.\n",
    "    \"\"\"\n",
    "    summary: str = Field(description=\"The summary of the text\")\n",
    "\n",
    "text_summarization_llm = model.with_structured_output(TextSummarization)\n",
    "\n",
    "class TitleGeneration(BaseModel):\n",
    "    \"\"\"\n",
    "    Generate the title of the text.\n",
    "    \"\"\"\n",
    "    title: str = Field(description=\"The title of the text\")\n",
    "\n",
    "title_generation_llm = model.with_structured_output(TitleGeneration)\n",
    "\n",
    "class ContentGeneration(BaseModel):\n",
    "    \"\"\"\n",
    "    Join the content of the text above and generate the content of the text.\n",
    "    \"\"\"\n",
    "    content: str = Field(description=\"The content of the text\")\n",
    "\n",
    "content_generation_llm = model.with_structured_output(ContentGeneration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb268753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LangGraph Node Functions ---\n",
    "\n",
    "def classify_text(state):\n",
    "    print('-> Calling text classification agent ->')\n",
    "\n",
    "    text_classification_system_prompt = \"\"\"\n",
    "    You are a text classification agent. You will be given a user query and you will need to classify the text into one of the following categories: News, Blog, Research, or Other.\n",
    "\n",
    "    Respond in json format with the following keys:\n",
    "\n",
    "    category: The category of the text. Must be one of \"News\", \"Blog\", \"Research\", or \"Other\".\n",
    "    \"\"\"\n",
    "\n",
    "    human_message = [msg for msg in state[\"messages\"] if isinstance(msg, HumanMessage)]\n",
    "    ai_message = [msg for msg in state[\"messages\"] if isinstance(msg, AIMessage)]\n",
    "    system_message = [SystemMessage(content=text_classification_system_prompt)]\n",
    "\n",
    "    messages = system_message + ai_message + human_message\n",
    "\n",
    "    result = text_classification_llm.invoke(messages)\n",
    "\n",
    "    # We only update the text_classification, not messages. The router will use the category.\n",
    "    return {\n",
    "        \"text_classification\": result.category\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_entities(state):\n",
    "    print(\"-> Calling entity extraction agent ->\")\n",
    "    entity_extraction_system_prompt = \"\"\"\n",
    "    You are an entity extraction agent. Extract entities from the provided text. \n",
    "    Return a dictionary with keys 'person', 'organisation', and 'location'.\n",
    "    Each key should map to a list of the corresponding entities found in the text.\n",
    "    Example: {\"person\": [\"John Doe\"], \"organisation\": [\"OpenAI\"], \"location\": [\"San Francisco\", \"India\"]}\n",
    "    If no entities are found, return an empty dictionary. If one key doesn't have a value, return an empty list for that key.\n",
    "    Respond in JSON format.\n",
    "    \"\"\"\n",
    "    human_message = [msg for msg in state[\"messages\"] if isinstance(msg, HumanMessage)]\n",
    "    ai_message = [msg for msg in state[\"messages\"] if isinstance(msg, AIMessage)]\n",
    "    system_message = [SystemMessage(content=entity_extraction_system_prompt)]\n",
    "    messages = system_message + ai_message + human_message\n",
    "    result = entity_extraction_llm.invoke(messages)\n",
    "    # We only update the entity_extraction, not messages. The router will use the extracted entities.\n",
    "    return {\n",
    "        \"entity_extraction\": result.entities\n",
    "    }\n",
    "\n",
    "def summarize_text(state):\n",
    "    print(\"-> Calling text summarization agent ->\")\n",
    "    human_message = [msg for msg in state[\"messages\"] if isinstance(msg, HumanMessage)]\n",
    "    ai_message = [msg for msg in state[\"messages\"] if isinstance(msg, AIMessage)]\n",
    "    system_message = [SystemMessage(content=text_summarization_system_prompt)]\n",
    "    messages = system_message + ai_message + human_message\n",
    "    result = text_summarization_llm.invoke(messages)\n",
    "    return {\"summary\": result.summary}\n",
    "    text = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
    "    summarization_prompt = (\n",
    "        \"You are a text summarization agent. Summarize the following text in 2-3 sentences, \"\n",
    "        \"focusing on the main points and omitting unnecessary details. \"\n",
    "        \"Be concise and clear.\\n\\n\"\n",
    "        f\"Text:\\n{text}\"\n",
    "    )\n",
    "    result = text_summarization_llm.invoke([HumanMessage(content=summarization_prompt)])\n",
    "    return {\"summary\": result.summary}\n",
    "\n",
    "def generate_title(state):\n",
    "    print(\"üè∑Ô∏è Generating title...\")\n",
    "    text = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
    "    result = title_generation_llm.invoke([HumanMessage(content=text)])\n",
    "    return {\"title\": result.title}\n",
    "\n",
    "def generate_content(state):\n",
    "    print(\"üì∞ Generating content...\")\n",
    "    # Compose content from previous steps\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "    entities = state.get(\"entity_extraction\", {})\n",
    "    category = state.get(\"text_classification\", \"\")\n",
    "    title = state.get(\"title\", \"\")\n",
    "    # Compose a prompt for content generation\n",
    "    prompt = (\n",
    "        f\"Title: {title}\\n\"\n",
    "        f\"Category: {category}\\n\"\n",
    "        f\"Summary: {summary}\\n\"\n",
    "        f\"Entities: {entities}\\n\"\n",
    "        \"Write a blog post using the above information.\"\n",
    "    )\n",
    "    result = content_generation_llm.invoke([HumanMessage(content=prompt)])\n",
    "    return {\"content\": result.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf660b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LangGraph Workflow Construction ---\n",
    "\n",
    "# Workflow\n",
    "# classify_text -> extract_entities -> summarize_text -> generate_title -> generate_content -> END\n",
    "\n",
    "graph = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes for each step\n",
    "graph.add_node(\"classify_text\", classify_text)\n",
    "graph.add_node(\"extract_entities\", extract_entities)\n",
    "graph.add_node(\"summarize_text\", summarize_text)\n",
    "graph.add_node(\"generate_title\", generate_title)\n",
    "graph.add_node(\"generate_content\", generate_content)\n",
    "\n",
    "# Define the workflow edges\n",
    "graph.add_edge(\"classify_text\", \"extract_entities\")\n",
    "graph.add_edge(\"extract_entities\", \"summarize_text\")\n",
    "graph.add_edge(\"summarize_text\", \"generate_title\")\n",
    "graph.add_edge(\"generate_title\", \"generate_content\")\n",
    "graph.add_edge(\"generate_content\", END)\n",
    "\n",
    "# Set the entry point\n",
    "graph.set_entry_point(\"classify_text\")\n",
    "\n",
    "# Compile the workflow app\n",
    "awesome_langgraph_workflow = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c769c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Example: Run the workflow on a sample paragraph ---\n",
    "\n",
    "# Example input paragraph (longer version)\n",
    "example_paragraph = (\n",
    "    \"Artificial intelligence (AI) is rapidly transforming industries across the globe. \"\n",
    "    \"From healthcare to finance, AI-powered solutions are enabling organizations to automate tasks, \"\n",
    "    \"gain insights from data, and improve decision-making. As technology advances, ethical considerations \"\n",
    "    \"and responsible AI development are becoming increasingly important to ensure positive societal impact. \"\n",
    "    \"In recent years, AI has also made significant strides in areas such as natural language processing, \"\n",
    "    \"computer vision, and robotics, leading to new applications that were previously unimaginable. \"\n",
    "    \"For example, AI-driven diagnostic tools are helping doctors detect diseases earlier and with greater accuracy, \"\n",
    "    \"while financial institutions use AI algorithms to detect fraud and manage risk. \"\n",
    "    \"Despite these advancements, challenges remain, including concerns about data privacy, algorithmic bias, \"\n",
    "    \"and the potential displacement of jobs. Addressing these issues requires collaboration between technologists, \"\n",
    "    \"policymakers, and society at large to create frameworks that promote transparency, fairness, and accountability. \"\n",
    "    \"Ultimately, the future of AI will depend on our ability to harness its power responsibly and for the benefit of all.\"\n",
    ")\n",
    "\n",
    "# Prepare the initial state for the workflow\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=example_paragraph)]\n",
    "}\n",
    "\n",
    "# Run the workflow\n",
    "result = awesome_langgraph_workflow.invoke(initial_state)\n",
    "\n",
    "# Print the results\n",
    "print(\"=== Workflow Output ===\")\n",
    "for key, value in result.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515e9dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06447d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84069df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6ebd89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306ff6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e047e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe9b570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbee426a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4143a214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ab66fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d063e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd219190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
